{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from decision_trees import *\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "\n",
    "base_forms = [\"adj\", \"adja\", \"adjc\", \"adjp\", \"adv\", \"burk\", \"depr\", \"ger\", \"conj\", \"comp\", \"num\", \"pact\",\n",
    "               \"pant\", \"pcon\", \"ppas\", \"ppron12\", \"ppron3\", \"pred\", \"prep\", \"siebie\", \"subst\", \"verb\", \"brev\",\n",
    "               \"interj\", \"qub\"]\n",
    "\n",
    "verb_forms = [\"nom\", \"gen\", \"acc\", \"dat\", \"inst\", \"loc\", \"voc\"]\n",
    "\n",
    "raw_form = {\"subst:nom\":[], \"subst:gen\":[], \"subst:acc\":[], \"subst:dat\":[], \"subst:inst\":[], \"subst:loc\":[], \"subst:voc\":[],\n",
    "            \"adj\":[], \"adja\":[], \"adjc\":[], \"adjp\":[], \"adv\":[], \"burk\":[], \"depr\":[], \"ger\":[], \"conj\":[], \"comp\":[], \"num\":[], \"pact\":[],\n",
    "            \"pant\":[], \"pcon\":[], \"ppas\":[], \"ppron12\":[], \"ppron3\":[], \"pred\":[], \"prep\":[], \"siebie\":[], \"verb\":[], \"brev\":[],\n",
    "            \"interj\":[], \"qub\":[], \"target\":[]}\n",
    "\n",
    "empty_form = {\"subst:nom\":0, \"subst:gen\":0, \"subst:acc\":0, \"subst:dat\":0, \"subst:inst\":0, \"subst:loc\":0, \"subst:voc\":0,\n",
    "            \"adj\":0, \"adja\":0, \"adjc\":0, \"adjp\":0, \"adv\":0, \"burk\":0, \"depr\":0, \"ger\":0, \"conj\":0, \"comp\":0, \"num\":0, \"pact\":0,\n",
    "            \"pant\":0, \"pcon\":0, \"ppas\":0, \"ppron12\":0, \"ppron3\":0, \"pred\":0, \"prep\":0, \"siebie\":0, \"verb\":0, \"brev\":0,\n",
    "            \"interj\":0, \"qub\":0, \"target\":0}\n",
    "\n",
    "\n",
    "signs = ['.', '(', ')', ';', '\"', '[', ']', ',', '?', '!', ':', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "polish = [('ź', 'z'), ('ż', 'z'), ('ą', 'a'), ('ę', 'e'), ('ó', 'o'), ('ł', 'l'), ('ć', 'c'), ('ń', 'n'), ('ś', 's')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(line):\n",
    "    line2 = []\n",
    "    line = line.split(' ')\n",
    "    for base in line:\n",
    "        base = base.lower()\n",
    "        for sign in signs:\n",
    "            base = base.replace(sign, ' ')\n",
    "        base = base.strip()\n",
    "        base = base.split(' ')\n",
    "        if base != '' and base != ['']:\n",
    "            line2.extend(base)\n",
    "\n",
    "    return line2\n",
    "\n",
    "\n",
    "def remove_polish(line):\n",
    "    line2 = []\n",
    "    for word in line:\n",
    "        for sign in polish:\n",
    "            word = word.replace(sign[0], sign[1])\n",
    "        line2.append(word)\n",
    "    return line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_big(line):\n",
    "    line2 = []\n",
    "    line = line.split(' ')\n",
    "    for base in line:\n",
    "        for sign in signs:\n",
    "            base = base.replace(sign, ' ')\n",
    "        base = base.strip()\n",
    "        base = base.split(' ')\n",
    "        if base != '' and base != ['']:\n",
    "            line2.extend(base)\n",
    "\n",
    "    return line2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polimorph(file='polimorfologik-2.1.txt'):\n",
    "    dictionary = {}\n",
    "    with open(file, 'r', encoding='utf8') as base_file:\n",
    "        for line in base_file:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(\";\")\n",
    "            line[2] = line[2].split(\"+\")\n",
    "            nl = []\n",
    "            for comp in line[2]:\n",
    "                spl = comp.split(\":\")\n",
    "                if spl[0] != \"subst\":\n",
    "                    if spl[0] not in nl:\n",
    "                        nl.append(spl[0])\n",
    "                else:\n",
    "                    if spl[0] + \":\" + spl[2] not in nl:\n",
    "                        nl.append(spl[0] + \":\" + spl[2])\n",
    "            line[2] = nl\n",
    "            dictionary[line[1]] = (line[0], line[2])\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def create_casts(base_poli):\n",
    "    dictionary = {}\n",
    "    for key in base_poli:\n",
    "        weak_key = remove_polish([key])[0]\n",
    "        if weak_key not in dictionary:\n",
    "            dictionary[weak_key] = []\n",
    "        dictionary[weak_key].append(key)\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polimorph2(file='polimorfologik-2.1.txt'):\n",
    "    dictionary = {}\n",
    "    with open(file, 'r', encoding='utf8') as base_file:\n",
    "        for line in base_file:\n",
    "            line = line.strip()\n",
    "            line = line.split(\";\")\n",
    "            if line[1].lower() != line[1]:\n",
    "                dictionary[line[1].lower()] = line[1]\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unigrams(file='1grams'):\n",
    "    dictionary = {}\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(' ')\n",
    "            dictionary[line[1]] = int(line[0])\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def load_2grams(file='2grams', k=5):\n",
    "    dictionary = {}\n",
    "    i = 0\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(' ')\n",
    "            if int(line[0]) >= k:\n",
    "                if line[1] not in dictionary:\n",
    "                    dictionary[line[1]] = {}\n",
    "                dictionary[line[1]][line[2]] = int(line[0])\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def load_3grams(file='3grams', k=5):\n",
    "    dictionary = {}\n",
    "    i = 0\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            line = line.strip().lower()\n",
    "            line = line.split(' ')\n",
    "            if int(line[0]) >= k:\n",
    "                if line[1] not in dictionary:\n",
    "                    dictionary[line[1]] = {}\n",
    "                dictionary[line[1]][line[2:]] = int(line[0])\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_set(file='train_shuf.txt', k=10000):\n",
    "    i = 0\n",
    "    lines = []\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            if i == k:\n",
    "                break\n",
    "            lines.append(tokenize(line))\n",
    "            i += 1\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def divide_set(total_set, k=0.7):\n",
    "    s = round(len(total_set)*k)\n",
    "    return total_set[:s], total_set[s:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_big_set(file='train_shuf.txt', k=10000):\n",
    "    i = 0\n",
    "    lines = []\n",
    "    with open(file, 'r', encoding='utf8') as base_vectors_lines:\n",
    "        for line in base_vectors_lines:\n",
    "            if i == k:\n",
    "                break\n",
    "            lines.append(tokenize_big(line))\n",
    "            i += 1\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(listt):\n",
    "        a = []\n",
    "        for itemm in listt:\n",
    "            if isinstance(itemm, list):\n",
    "                a += flatten(itemm)\n",
    "            else:\n",
    "                a.append(itemm)\n",
    "        return a\n",
    "\n",
    "def combine(lines):\n",
    "    conc = lines[0]\n",
    "    if len(lines) == 1:\n",
    "        conc = [conc]\n",
    "    for part in lines[1:]:\n",
    "        conc = list(map(list, itertools.product(conc, part)))\n",
    "    conc2 = []\n",
    "    for item in conc:\n",
    "        conc2.append(flatten(item))\n",
    "    return conc2\n",
    "\n",
    "def permute(line, casts):\n",
    "    line2 = []\n",
    "    for word in line:\n",
    "        if word in casts:\n",
    "            line2.append(casts[word])\n",
    "        else:\n",
    "            line2.append([word])\n",
    "\n",
    "    return combine(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, None], ['a', None]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine([[None, \"a\"], [None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong(line, casts):\n",
    "    if line not in permute(line, casts):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(line, k=3):\n",
    "    \n",
    "    line2 = []\n",
    "    line2.append(None)\n",
    "    line2 += line\n",
    "    line2.append(None)\n",
    "    line = line2\n",
    "    \n",
    "    if len(line) < k:\n",
    "        line2 = []\n",
    "        for i in range(math.ceil((k-len(line))/2)):\n",
    "            line2.append(None)\n",
    "        line2 += line\n",
    "        for i in range(math.floor((k-len(line))/2)):\n",
    "            line2.append(None)\n",
    "        line = line2\n",
    "        \n",
    "    if len(line) == k:\n",
    "        return [line]\n",
    "    \n",
    "    else:\n",
    "        lines = []\n",
    "        line2 = line[0:k]\n",
    "        lines.append(line2.copy())\n",
    "        for word in line[k:]:\n",
    "            del line2[0]\n",
    "            line2.append(word)\n",
    "            lines.append(line2.copy())\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dgrams(training_set, casts):\n",
    "    dgrams = {}\n",
    "    for line in training_set:\n",
    "        if len(line) >= 2:\n",
    "            fst = line[0]\n",
    "            for word in line[1:]:\n",
    "                snd = word\n",
    "                if not wrong([fst, snd], casts):\n",
    "                    if fst not in dgrams:\n",
    "                        dgrams[fst] = {}\n",
    "                    if snd not in dgrams[fst]:\n",
    "                        dgrams[fst][snd] = 0\n",
    "                    dgrams[fst][snd] += 1\n",
    "                fst = snd\n",
    "    \n",
    "    return dgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(training_set, poli, casts, digrams1, digrams2):\n",
    "    # df = pd.DataFrame(data=raw_form)\n",
    "    # duos = pd.DataFrame(data={\"fst\":[], \"snd\":[], \"target\":[]})\n",
    "    # trios = pd.DataFrame(data={\"fst\":[], \"snd\":[], \"trd\":[], \"target\":[]})\n",
    "    trios = []\n",
    "    j = -1\n",
    "    for base_line in training_set:\n",
    "        j += 1\n",
    "        if j % 10000 == 0:\n",
    "            print(j)\n",
    "\n",
    "        for line in windows(base_line, k=3):\n",
    "            if not wrong(line, casts):\n",
    "                for perm in permute(line, casts):\n",
    "                    trio = {\"fst\":0, \"snd\":0, \"trd\":0, \"lgram\":\"n\", \"rgram\":\"n\", \"target\":0}\n",
    "                    \n",
    "                    if line == perm:\n",
    "                        trio[\"target\"] = \"y\"\n",
    "                    else:\n",
    "                        trio[\"target\"] = \"n\"\n",
    "                        \n",
    "                    if perm[0] in digrams1:\n",
    "                        if perm[1] in digrams1[perm[0]]:\n",
    "                            trio[\"lgram\"] = \"y\"\n",
    "                    #if perm[0] in digrams2:\n",
    "                    #    if perm[1] in digrams2[perm[0]]:\n",
    "                    #        trio[\"lgram\"] = \"y\"\n",
    "                    if perm[1] in digrams1:\n",
    "                        if perm[2] in digrams1[perm[1]]:\n",
    "                            trio[\"rgram\"] = \"y\"\n",
    "                    #if perm[1] in digrams2:\n",
    "                    #    if perm[2] in digrams2[perm[1]]:\n",
    "                    #        trio[\"rgram\"] = \"y\"\n",
    "                                \n",
    "                    \n",
    "                    form = []\n",
    "                    bad = False\n",
    "                    for word in perm:\n",
    "                        if word in poli:\n",
    "                            form.append(poli[word][1])\n",
    "                        else:\n",
    "                            if word == None:\n",
    "                                form.append([None])\n",
    "                            else:\n",
    "                                form.append([\"na\"])\n",
    "                    \n",
    "                    if not bad:\n",
    "                        form = combine(form)\n",
    "                        for comb in form:\n",
    "                            trio[\"fst\"] = comb[0]\n",
    "                            trio[\"snd\"] = comb[1]\n",
    "                            trio[\"trd\"] = comb[2]\n",
    "                            trios.append(trio)\n",
    "\n",
    "    trios = pd.DataFrame(trios)\n",
    "    return trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_big(training_set):\n",
    "    dictionary = {}\n",
    "    for line in training_set:\n",
    "        if len(line) >= 2:\n",
    "            for word in line[1:]:\n",
    "                if len(word) > 0:\n",
    "                    if word[0].lower() != word[0]:\n",
    "                        if word.lower() not in dictionary:\n",
    "                            dictionary[word.lower()] = [word, 0, 0]\n",
    "                        dictionary[word.lower()][1] += 1\n",
    "                        dictionary[word.lower()][2] += 1\n",
    "                    else:\n",
    "                        if word in dictionary:\n",
    "                            dictionary[word][2] += 1\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "           fst        snd   trd lgram rgram target\n",
      "0         None  subst:gen    na     n     n      y\n",
      "1    subst:gen         na  verb     n     n      y\n",
      "2           na       verb  verb     n     n      y\n",
      "3         verb       verb   num     n     y      y\n",
      "4         verb       verb   num     n     y      y\n",
      "..         ...        ...   ...   ...   ...    ...\n",
      "247  subst:gen       prep  verb     y     y      y\n",
      "248       prep       verb  None     y     n      y\n",
      "249       prep       verb  None     y     n      y\n",
      "250       prep       verb  None     y     n      y\n",
      "251       prep       verb  None     y     n      y\n",
      "\n",
      "[252 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(create_database(load_set(k=3), Gpoli, Gcasts, Gdigrams1, Gdigrams2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_digrams(digrams):\n",
    "    for fst in digrams:\n",
    "        count = 0\n",
    "        for snd in digrams[fst]:\n",
    "            count += digrams[fst][snd]\n",
    "        digrams[fst][0] = count\n",
    "    return digrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_polish2(phrase, casts, digrams1, digrams2):\n",
    "    perms = []\n",
    "    i = 0\n",
    "    for line in windows(phrase, k=2):\n",
    "        perms.append([])\n",
    "        best_perm = None\n",
    "        bsc = -1\n",
    "        for perm in permute(line, casts):\n",
    "            pres = 0\n",
    "            size = 1\n",
    "            if perm[0] in digrams1:\n",
    "                if perm[1] in digrams1[perm[0]]:\n",
    "                    pres += digrams1[perm[0]][perm[1]]\n",
    "                size += digrams1[perm[1]][0]\n",
    "            if perm[0] in digrams2:\n",
    "                if perm[1] in digrams2[perm[0]]:\n",
    "                    pres += digrams2[perm[0]][perm[1]]\n",
    "                size += digrams2[perm[1]][0]\n",
    "            score = (pres/size) * math.log(size)\n",
    "            perms[i].append((perm,score))\n",
    "        i += 1\n",
    "    \n",
    "    output = []\n",
    "    prev = None\n",
    "    for i in range(len(perms)):\n",
    "        mx = -1\n",
    "        mperm = None\n",
    "        for perm, sc in perms[i]:\n",
    "            if perm[0] == prev:\n",
    "                if sc > mx:\n",
    "                    mx = sc\n",
    "                    mperm = perm\n",
    "        output.append(mperm[1])\n",
    "        prev = mperm[1]           \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_polish(phrase, poli, casts, digrams1, digrams2, main_tree):\n",
    "    ans = {}\n",
    "    for i in range(len(phrase)+2):\n",
    "        ans[i] = []\n",
    "    \n",
    "    perms = []\n",
    "    i = 0\n",
    "    for line in windows(phrase, k=3):\n",
    "        perms.append([])\n",
    "        i += 1\n",
    "        mx = 0\n",
    "        mn = 0\n",
    "        mxperm = line\n",
    "        for perm in permute(line, casts):          \n",
    "            entry = {\"fst\":0, \"snd\":0, \"trd\":0, \"lgram\":\"n\", \"rgram\":\"n\"}\n",
    "            if perm[0] in digrams1:\n",
    "                if perm[1] in digrams1[perm[0]]:\n",
    "                    entry[\"lgram\"] = \"y\"\n",
    "            if perm[0] in digrams2:\n",
    "                if perm[1] in digrams2[perm[0]]:\n",
    "                    entry[\"lgram\"] = \"y\"\n",
    "            if perm[1] in digrams1:\n",
    "                if perm[2] in digrams1[perm[1]]:\n",
    "                    entry[\"rgram\"] = \"y\"\n",
    "            if perm[1] in digrams2:\n",
    "                if perm[2] in digrams2[perm[1]]:\n",
    "                    entry[\"rgram\"] = \"y\"\n",
    "\n",
    "            forms = []\n",
    "            for word in perm:\n",
    "                if word in poli:\n",
    "                    forms.append(poli[word][1])\n",
    "                else:\n",
    "                    if word == None:\n",
    "                        forms.append([None])\n",
    "                    else:\n",
    "                        forms.append([\"na\"])\n",
    "\n",
    "            forms = combine(forms)\n",
    "            \n",
    "            #mn1 = 1\n",
    "            #mx1 = 0\n",
    "            ttl = 0\n",
    "            for form in forms:\n",
    "                entry[\"fst\"] = form[0]\n",
    "                entry[\"snd\"] = form[1]\n",
    "                entry[\"trd\"] = form[2]\n",
    "                sc1 = main_tree.classify(entry)\n",
    "                #print(perm)\n",
    "                #print(entry, score)\n",
    "                ttl += sc1*sc1\n",
    "                #if sc1 > mx1:\n",
    "                #    mx1 = sc1\n",
    "                #if sc1 < mn1:\n",
    "                #    mn1 = sc1\n",
    "            #if 0.5 - mn1 >= mx1 - 0.5:\n",
    "            #    entry[\"trio\"] = mn1\n",
    "            #else:\n",
    "            #    entry[\"trio\"] = mx1\n",
    "            sc1 = ttl/len(forms)\n",
    "            perms[i-1].append((perm, sc1))\n",
    "            if sc1 > mx:\n",
    "                mx = sc1\n",
    "                mperm = perm\n",
    "                \n",
    "\n",
    "        #ans[i-1].append((mperm[0], mx))\n",
    "        #ans[i].append((mperm[1], mx))\n",
    "        #ans[i+1].append((mperm[2], mx))\n",
    "\n",
    "    output = []\n",
    "    prev = None\n",
    "    for i in range(len(perms)):\n",
    "        mx = -1\n",
    "        mperm = None\n",
    "        for perm, sc in perms[i]:\n",
    "            if perm[0] == prev:\n",
    "                if sc > mx:\n",
    "                    mx = sc\n",
    "                    mperm = perm\n",
    "        output.append(mperm[1])\n",
    "        prev = mperm[1]\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(1,len(phrase)+1):\n",
    "        mx = 0\n",
    "        oword = None\n",
    "        for word, sc in ans[i]:\n",
    "            if sc > mx:\n",
    "                mx = sc\n",
    "                oword = word\n",
    "        output.append(oword)\n",
    "    \"\"\"\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_case(phrase, bigs1, bigs2):\n",
    "    ww = phrase[0]\n",
    "    fixed = []\n",
    "    fixed.append(ww.capitalize())\n",
    "    if len(phrase) >= 2:\n",
    "        for word in phrase[1:]:\n",
    "            if word in bigs1 and (word not in bigs2 or (word in bigs2 and bigs2[word][1] / bigs2[word][2] >= 0.5)):\n",
    "                fixed.append(bigs1[word])\n",
    "            else:\n",
    "                if word in bigs2 and bigs2[word][1] / bigs2[word][2] > 0.5:\n",
    "                    fixed.append(bigs2[word][0])\n",
    "                else:\n",
    "                    fixed.append(word)\n",
    "    \n",
    "    return fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(phrase1, phrase2):\n",
    "    s = 0\n",
    "    for i in range(len(phrase1)):\n",
    "        if phrase1[i] == phrase2[i]:\n",
    "            s += 1\n",
    "\n",
    "    return s/len(phrase1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gpoli = load_polimorph()\n",
    "Gcasts = create_casts(Gpoli)\n",
    "#unigramsS = load_unigrams()\n",
    "Gdigrams1 = load_2grams(k=3)\n",
    "#trigramsS = load_3grams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gbig = load_polimorph2()\n",
    "Gtotal_set = load_big_set(k=1000000)\n",
    "\n",
    "Gbig2 = find_big(Gtotal_set)\n",
    "del Gtotal_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gtotal_set = load_set(k=1000000)\n",
    "Gdigrams2 = create_dgrams(Gtotal_set, Gcasts)\n",
    "del Gtotal_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gvalidation_set = load_set(k=1200000)[1000000:]\n",
    "Gvalidation_set2 = load_big_set(k=1200000)[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gdigrams1 = count_digrams(Gdigrams1)\n",
    "Gdigrams2 = count_digrams(Gdigrams2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gtrain_set = load_set(k=1000000)\n",
    "print(len(Gtrain_set))\n",
    "\n",
    "Gdatabase = create_database(Gtrain_set, Gpoli, Gcasts, Gdigrams1, Gdigrams2)\n",
    "del Gtrain_set\n",
    "\n",
    "Gmain_tree = Tree(Gdatabase)\n",
    "del Gdatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "Gtrain_set = load_set(k=120000)[100000:]\n",
    "trios2 = create_database(Gtrain_set, Gpoli, Gcasts, Gdigrams1, Gdigrams2)\n",
    "del Gtrain_set\n",
    "Gmain_tree.start_prune(trios2)\n",
    "del trios2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gmain_tree.draw().render('test-output/database_tree.gv', view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['parlament', 'zdecydował', 'jednak', 'inaczej', 'i', 'przyjął', 'w', 'ustawie', 'z', 'dnia', 'r', 'jednoinstancyjne', 'postępowanie', 'orzeczniczo-lekarskie']\n",
      "['parlament', 'zdecydował', 'jednak', 'inaczej', 'i', 'przyjął', 'w', 'ustawie', 'z', 'dnia', 'r', 'jednoinstancyjne', 'postępowanie', 'orzeczniczo-lekarskie']\n",
      "['parlament', 'zdecydowal', 'jednak', 'inaczej', 'i', 'przyjal', 'w', 'ustawie', 'z', 'dnia', 'r', 'jednoinstancyjne', 'postepowanie', 'orzeczniczo-lekarskie']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "line = load_set(k=3)[1]\n",
    "print(fix_polish(remove_polish(line), Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree))\n",
    "print(line)\n",
    "print(remove_polish(line))\n",
    "print(score(line, fix_polish(remove_polish(line), Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "0.9569000682611913\n"
     ]
    }
   ],
   "source": [
    "#k=20000\n",
    "print(len(Gvalidation_set))\n",
    "total = 0\n",
    "\n",
    "for i in range(len(Gvalidation_set)):\n",
    "    line = Gvalidation_set[i]\n",
    "    line2 = Gvalidation_set2[i]\n",
    "    broken_line = remove_polish(line)\n",
    "    fixed_line = fix_polish(broken_line, Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree)\n",
    "    sc1 = score(line, fixed_line)\n",
    "    fixed_line2 = fix_case(fixed_line, Gbig, Gbig2)\n",
    "    sc2 = score(line2, fixed_line2)\n",
    "    #print(fixed_line2)\n",
    "    #print(line2)\n",
    "    #print(sc1, sc2)\n",
    "    total += math.sqrt(sc1*sc1)\n",
    "\n",
    "print(total/len(Gvalidation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "0.9312928879197104\n"
     ]
    }
   ],
   "source": [
    "#k=20000\n",
    "print(len(Gvalidation_set))\n",
    "total = 0\n",
    "\n",
    "for i in range(len(Gvalidation_set)):\n",
    "    line = Gvalidation_set[i]\n",
    "    line2 = Gvalidation_set2[i]\n",
    "    broken_line = remove_polish(line)\n",
    "    fixed_line = fix_polish(broken_line, Gpoli, Gcasts, Gdigrams1, Gdigrams2, Gmain_tree)\n",
    "    sc1 = score(line, fixed_line)\n",
    "    fixed_line2 = fix_case(fixed_line, Gbig, Gbig2)\n",
    "    sc2 = score(line2, fixed_line2)\n",
    "    #print(fixed_line2)\n",
    "    #print(line2)\n",
    "    #print(sc1, sc2)\n",
    "    total += math.sqrt(sc1*sc2)\n",
    "\n",
    "print(total/len(Gvalidation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "0.9449862768483344\n"
     ]
    }
   ],
   "source": [
    "print(len(Gvalidation_set))\n",
    "total = 0\n",
    "\n",
    "k = 100\n",
    "for i in range(k):\n",
    "    line = Gvalidation_set[i]\n",
    "    line2 = Gvalidation_set2[i]\n",
    "    broken_line = remove_polish(line)\n",
    "    fixed_line = fix_polish2(broken_line, Gcasts, Gdigrams1, Gdigrams2)\n",
    "    sc1 = score(line, fixed_line)\n",
    "    fixed_line2 = fix_case(fixed_line, Gbig, Gbig2)\n",
    "    sc2 = score(line2, fixed_line2)\n",
    "    #print(fixed_line2)\n",
    "    #print(line2)\n",
    "    #print(sc1, sc2)\n",
    "    total += math.sqrt(sc1*sc2)\n",
    "\n",
    "print(total/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 3077, 607097]\n"
     ]
    }
   ],
   "source": [
    "print(Gbig2[\"w\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 21, 'dużo': 17, 'na': 16, '-': 12, 'za': 11, 'z': 8, 'tak': 7, 'alkoholu': 6, 'do': 6, 'wodę': 6, 'już': 5, 'mleko': 5, 'mleko,': 5, 'pij': 5, 'w': 5}\n"
     ]
    }
   ],
   "source": [
    "print(Gdigrams1[\"pij\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'świeżo': 1, 'wodę': 1, 'piotrek-elektryczne': 1, 'tylko': 1, 'nych': 1, 'skim': 1, 'i': 1, 'na': 1}\n"
     ]
    }
   ],
   "source": [
    "print(Gdigrams2[\"pij\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'świeżo': 1, 'wodę': 1, 'piotrek-elektryczne': 1, 'tylko': 1, 'nych': 1, 'skim': 1, 'i': 1, 'na': 1}\n"
     ]
    }
   ],
   "source": [
    "print(Gdigrams2[\"pij\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jeśli']\n"
     ]
    }
   ],
   "source": [
    "print(Gcasts[\"jesli\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
